{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "triplet_loss_keras_no_distance_layer_64_64_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/zeeshanhaider1007/MatchNet-with-Triplet-Loss/blob/master/triplet_loss_keras_no_distance_layer_64_64_1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "j6uWOTX2eng9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2327
        },
        "outputId": "fb4f44c1-ada6-4ee6-8e82-2112ea3e4196"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18396 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\r\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmpahy1ibhx/pubring.gpg' created\n",
            "gpg: /tmp/tmpahy1ibhx/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19804 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "figPK1oiexGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FVmaY9GIfKBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "69c007ee-106c-45b1-a6a8-64af3d745006"
      },
      "cell_type": "code",
      "source": [
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_XFVCJpkgPQX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p my_drive\n",
        "!google-drive-ocamlfuse my_drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8I2ZEfgkpht6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d018e3a-a79b-4221-8ac6-f0912fb0e70c"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import sys\n",
        "import random\n",
        "import h5py\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.models import *\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, Lambda,Conv2D, MaxPooling2D,concatenate,Concatenate,BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kDqi8Sjvphuq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68c0ba60-621d-42c0-e29a-92645796ba4a"
      },
      "cell_type": "code",
      "source": [
        "epoch = 80\n",
        "Batch_Size=64\n",
        "learning_rate=1e-3\n",
        "name=\"triplet_dataset123\"\n",
        "path= './my_drive/app/'\n",
        "data_path = path+name\n",
        "\n",
        "print(data_path)\n",
        "activ=\"LeakyReLU\"\n",
        "##name of storing models\n",
        "#dataset_activation_epochs\n",
        "FC_model=path+\"_\"+name+\"_\"+activ+\"LeakyReLU_bachnormalization\"+\"_80_FC_modified_triplet_weights.h5\"\n",
        "feature_model=path+\"_\"+name+\"_\"+activ+\"LeakyReLU_batchnormalization\"+\"_80_feature_model_.h5\"\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./my_drive/app/triplet_dataset123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yio94Z6dpzgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z9sf0HY5phu_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(data_path):\n",
        "    with h5py.File(data_path+\".h5\",'r') as hdf: \n",
        "#    hdf.create_dataset(name=\"anchor_pairs\",data=x_train))\n",
        "        x=np.array(hdf.get(\"anchor_pairs\"))\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tKG8P5_aphvZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L9otQ9guphvv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    print (\"euclidean shape\",(shape1[0], 1))\n",
        "    return (shape1[0], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PerstTiHphv7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    '''\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) +\n",
        "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e1rKSr_3phwK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "    \"\"\"\n",
        "    Implementation of the triplet loss function\n",
        "    Arguments:\n",
        "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor data\n",
        "            positive -- the encodings for the positive data (similar to anchor)\n",
        "            negative -- the encodings for the negative data (different from anchor)\n",
        "    Returns:\n",
        "    loss -- real number, value of the loss\n",
        "    \"\"\"\n",
        "    print (\"predicted tensor\")\n",
        "    print (y_pred.shape)\n",
        "    anchor=y_pred[:,0:4096]\n",
        "    positive = y_pred[:,4096:8192]\n",
        "    print (\"positive loss\",positive.shape)\n",
        "    negative = y_pred[:,8192:12288]\n",
        "    print (\"negative loss\",negative.shape)\n",
        "\n",
        "    # distance between \n",
        "\n",
        "    # compute loss\n",
        "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
        "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
        "\n",
        "    # compute loss\n",
        "    basic_loss = pos_dist-neg_dist+alpha\n",
        "    loss = K.maximum(basic_loss,0.0)\n",
        "    print (\"loss\",loss)\n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f0EZRiygphwZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_base_network(input_shape):\n",
        "    '''Base network to be shared (eq. to feature extraction).\n",
        "    '''\n",
        "    print (\"entering network\")\n",
        "    input = Input(shape=input_shape)\n",
        "    print (input.shape)\n",
        "    x=Conv2D(24, (7, 7),strides=1,kernel_initializer=\"glorot_normal\", padding='same')(input)\n",
        "    x=BatchNormalization(momentum=0.99, epsilon=0.001, beta_initializer='zeros', gamma_initializer='ones')(x)\n",
        "    x=LeakyReLU(alpha=.001)(x)\n",
        "    print (x.shape)\n",
        "    x=MaxPooling2D((2, 2),strides=2)(x)\n",
        "    print (x.shape)\n",
        "    x=Conv2D(64, (5, 5),strides=1, kernel_initializer=\"glorot_normal\", padding='same')(x)\n",
        "    x=BatchNormalization(momentum=0.99, epsilon=0.001, beta_initializer='zeros', gamma_initializer='ones')(x)\n",
        "    x=LeakyReLU(alpha=.001)(x)\n",
        "    print (x.shape)\n",
        "    x=MaxPooling2D((2, 2),strides=2)(x)\n",
        "    print (x.shape)\n",
        "    x=Conv2D(96, (3, 3),strides=1 ,kernel_initializer=\"glorot_normal\", padding='same')(x)\n",
        "    x=BatchNormalization(momentum=0.99, epsilon=0.001, beta_initializer='zeros', gamma_initializer='ones')(x)\n",
        "    x=LeakyReLU(alpha=.001)(x)\n",
        "    print (x.shape)\n",
        "    x=Conv2D(96, (2, 2),strides=1,kernel_initializer=\"glorot_normal\", padding='same')(x)\n",
        "    x=BatchNormalization(momentum=0.99, epsilon=0.001, beta_initializer='zeros', gamma_initializer='ones')(x)\n",
        "    x=LeakyReLU(alpha=.001)(x)\n",
        "    print (x.shape)\n",
        "    x=Conv2D(64, (3, 3),strides=1,kernel_initializer=\"glorot_normal\", padding='same')(x)\n",
        "    x=BatchNormalization(momentum=0.99, epsilon=0.001, beta_initializer='zeros', gamma_initializer='ones')(x)\n",
        "    x=LeakyReLU(alpha=.001)(x)\n",
        "    print (x.shape)\n",
        "    x=MaxPooling2D((2, 2),strides=2)(x)\n",
        "    print (x.shape)\n",
        "    x=Flatten()(x)\n",
        "    print (x.shape)\n",
        "    print (\"exiting network\")\n",
        "    return Model(input, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A8F1R04_phww",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    pred = y_pred.ravel() < 0.5\n",
        "    return np.mean(pred == y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "agIMP4KmphxP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FhLT7uGvphx2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1cebc7b9-c461-4082-8eea-709f6c969ab1"
      },
      "cell_type": "code",
      "source": [
        "##comparison  anchor\n",
        "print(data_path)\n",
        "x=load_data(data_path)\n",
        "x=np.array((x),dtype=np.uint8)\n",
        "data_instances=x.shape[0]\n",
        "print (x.shape)\n",
        "\n",
        "#Image.fromarray(x[10,0,:,:,:],'RGB').show()\n",
        "#Image.fromarray(x[10,1,:,:,:],'RGB').show()\n",
        "#Image.fromarray(x[10,2,:,:,:],'RGB').show()\n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./my_drive/app/triplet_dataset123\n",
            "(10000, 3, 64, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "alktR8SVphyX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "92422c2c-c685-4770-be12-ab9f10288dd1"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "f, (ax1, ax2,ax3) = plt.subplots(1, 3, sharey=True)\n",
        "num=int(random.randint(1,data_instances)%data_instances)\n",
        "#anchor_im=[255*(x[d,0,:,:]/x[d,0,:,:].max())for d in range(data_instances)]\n",
        "#pos_im=[255*x[d,0,:,:]/x[d,0,:,:].max() for d in range(data_instances)]\n",
        "#neg_im=[255*x[d,0,:,:]/x[d,0,:,:].max() for d in range(data_instances)]\n",
        "#anchor_im=np.array((anchor_im), dtype =np.uint8)\n",
        "#img = anchor_im.astype(np.uint8)\n",
        "#ax1.imshow(img[0,:,:])\n",
        "ax1.imshow(x[num,0,:,:])\n",
        "ax1.set_title('anchor')\n",
        "ax2.imshow(x[num,1,:,:])\n",
        "ax2.set_title('positive')\n",
        "ax3.imshow(x[num,2,:,:])\n",
        "ax3.set_title('negative')\n",
        "print (x.shape)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 3, 64, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFZCAYAAADZ6SWdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f69ce730f60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8AyCSJiWphy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d72888b5-b2b9-4f62-c567-fcd950e0d8ea"
      },
      "cell_type": "code",
      "source": [
        "print (num)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jg6MbH-uphzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "59c68aa5-da5b-425f-db10-75874c495945"
      },
      "cell_type": "code",
      "source": [
        "in_dims = (64,64,1)\n",
        "out_dims = (8,8,64)\n",
        "\n",
        "# Network definition\n",
        "#with tf.device(tf_device):\n",
        "\n",
        "# Create the 3 inputs\n",
        "anchor_in = Input(shape=in_dims,name=\"anchor\")\n",
        "pos_in = Input(shape=in_dims,name=\"positive\")\n",
        "neg_in = Input(shape=in_dims,name=\"negative\")\n",
        "\n",
        "# Share base network with the 3 inputs\n",
        "base_network = create_base_network(in_dims)\n",
        "anchor_out = base_network(anchor_in)\n",
        "pos_out = base_network(pos_in)\n",
        "neg_out = base_network(neg_in)\n",
        "\n",
        "#lamda layer\n",
        "#pos_distance = Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([anchor_out,pos_out])\n",
        "#print (\"positive dist\",pos_distance.shape)\n",
        "#neg_distance = Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([anchor_out,neg_out])\n",
        "#print (\"negative dist\",neg_distance.shape)\n",
        "\n",
        "#\n",
        "#print (\"concatenated\",merged_vector.shape)\n",
        "#model = Model(inputs=[anchor_in, pos_in, neg_in], outputs=merged_vector)\n",
        "\n",
        "merged_vector = concatenate([anchor_out, pos_out, neg_out],axis=-1)\n",
        "\n",
        "# Define the trainable model\n",
        "model = Model(inputs=[anchor_in, pos_in, neg_in], outputs=merged_vector)\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entering network\n",
            "(?, 64, 64, 1)\n",
            "(?, 64, 64, 24)\n",
            "(?, 32, 32, 24)\n",
            "(?, 32, 32, 64)\n",
            "(?, 16, 16, 64)\n",
            "(?, 16, 16, 96)\n",
            "(?, 16, 16, 96)\n",
            "(?, 16, 16, 64)\n",
            "(?, 8, 8, 64)\n",
            "(?, ?)\n",
            "exiting network\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WtOC6v0Aphzt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2937
        },
        "outputId": "ff2245c0-2547-429e-d17f-fb8f606d0dc7"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(lr=learning_rate),\n",
        "              loss=triplet_loss)\n",
        "#sys.exit(0)\n",
        "y_dummie=np.zeros((len(x)))\n",
        "# Training the model\n",
        "x=np.reshape((x),(10000,3,64,64,1))\n",
        "model.fit([x[:,0,:,:],x[:,1,:,:],x[:,2,:,:]], y_dummie,validation_split=0.2,batch_size=64, epochs=epoch)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted tensor\n",
            "(?, ?)\n",
            "positive loss (?, ?)\n",
            "negative loss (?, ?)\n",
            "loss Tensor(\"loss_9/concatenate_7_loss/Maximum:0\", shape=(?,), dtype=float32)\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/80\n",
            "8000/8000 [==============================] - 25s 3ms/step - loss: 7.5858 - val_loss: 0.6886\n",
            "Epoch 2/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.2848 - val_loss: 0.3046\n",
            "Epoch 3/80\n",
            "2496/8000 [========>.....................] - ETA: 13s - loss: 0.1300"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.1340 - val_loss: 0.1891\n",
            "Epoch 4/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0840 - val_loss: 0.1088\n",
            "Epoch 5/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0606 - val_loss: 0.0791\n",
            "Epoch 6/80\n",
            "6528/8000 [=======================>......] - ETA: 3s - loss: 0.0487"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0462 - val_loss: 0.0690\n",
            "Epoch 7/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0357 - val_loss: 0.0573\n",
            "Epoch 8/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0296 - val_loss: 0.0488\n",
            "Epoch 9/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0261"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0251 - val_loss: 0.0488\n",
            "Epoch 10/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0233 - val_loss: 1.2207\n",
            "Epoch 11/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0197 - val_loss: 0.0383\n",
            "Epoch 12/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0184"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0181 - val_loss: 0.0340\n",
            "Epoch 13/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0165 - val_loss: 0.0324\n",
            "Epoch 14/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0148 - val_loss: 0.0309\n",
            "Epoch 15/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0143"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0150 - val_loss: 0.0304\n",
            "Epoch 16/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0130 - val_loss: 0.0298\n",
            "Epoch 17/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0117 - val_loss: 0.0322\n",
            "Epoch 18/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0108"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0110 - val_loss: 0.0283\n",
            "Epoch 19/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0116 - val_loss: 0.0273\n",
            "Epoch 20/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0108 - val_loss: 0.0292\n",
            "Epoch 21/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0085"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0092 - val_loss: 0.0280\n",
            "Epoch 22/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0101 - val_loss: 0.0277\n",
            "Epoch 23/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0089 - val_loss: 0.0256\n",
            "Epoch 24/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0095"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0093 - val_loss: 0.0254\n",
            "Epoch 25/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0072 - val_loss: 0.0273\n",
            "Epoch 26/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0086 - val_loss: 0.0259\n",
            "Epoch 27/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0062"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0064 - val_loss: 0.0279\n",
            "Epoch 28/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0066 - val_loss: 0.0264\n",
            "Epoch 29/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0106 - val_loss: 0.1056\n",
            "Epoch 30/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0061"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0064 - val_loss: 0.0265\n",
            "Epoch 31/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0082 - val_loss: 0.0327\n",
            "Epoch 32/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0084 - val_loss: 0.0367\n",
            "Epoch 33/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0068"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0073 - val_loss: 0.0291\n",
            "Epoch 34/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0066 - val_loss: 0.2282\n",
            "Epoch 35/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0076 - val_loss: 0.0311\n",
            "Epoch 36/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0081"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0076 - val_loss: 0.0262\n",
            "Epoch 37/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0060 - val_loss: 0.0254\n",
            "Epoch 38/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0081 - val_loss: 0.0296\n",
            "Epoch 39/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0055"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0052 - val_loss: 0.0310\n",
            "Epoch 40/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0067 - val_loss: 0.0277\n",
            "Epoch 41/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0057 - val_loss: 0.0237\n",
            "Epoch 42/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0069"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0068 - val_loss: 0.0402\n",
            "Epoch 43/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0065 - val_loss: 0.2350\n",
            "Epoch 44/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0061 - val_loss: 0.0321\n",
            "Epoch 45/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0080"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0076 - val_loss: 0.0261\n",
            "Epoch 46/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0041 - val_loss: 0.0246\n",
            "Epoch 47/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0055 - val_loss: 0.0285\n",
            "Epoch 48/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0045"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0045 - val_loss: 0.0266\n",
            "Epoch 49/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0058 - val_loss: 0.0268\n",
            "Epoch 50/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0061 - val_loss: 0.0294\n",
            "Epoch 51/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0047 - val_loss: 0.0457\n",
            "Epoch 52/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0046 - val_loss: 0.0265\n",
            "Epoch 53/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0050 - val_loss: 0.0379\n",
            "Epoch 54/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0038"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0038 - val_loss: 0.0337\n",
            "Epoch 55/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0057 - val_loss: 0.0422\n",
            "Epoch 56/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0056 - val_loss: 0.0237\n",
            "Epoch 57/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0049"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0051 - val_loss: 0.2529\n",
            "Epoch 58/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0030 - val_loss: 0.0288\n",
            "Epoch 59/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0035 - val_loss: 0.0323\n",
            "Epoch 60/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0050"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0050 - val_loss: 0.0221\n",
            "Epoch 61/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0051 - val_loss: 0.1870\n",
            "Epoch 62/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0036 - val_loss: 0.0243\n",
            "Epoch 63/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0042"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0046 - val_loss: 0.0349\n",
            "Epoch 64/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0045 - val_loss: 0.0268\n",
            "Epoch 65/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0050 - val_loss: 0.0224\n",
            "Epoch 66/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0025"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0027 - val_loss: 0.0719\n",
            "Epoch 67/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0029 - val_loss: 0.0344\n",
            "Epoch 68/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0041 - val_loss: 0.0287\n",
            "Epoch 69/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0036"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0038 - val_loss: 0.0324\n",
            "Epoch 70/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0042 - val_loss: 0.0200\n",
            "Epoch 71/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0041 - val_loss: 0.0257\n",
            "Epoch 72/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0048"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0046 - val_loss: 0.0250\n",
            "Epoch 73/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0024 - val_loss: 0.0210\n",
            "Epoch 74/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0036 - val_loss: 0.0296\n",
            "Epoch 75/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0035 - val_loss: 0.0219\n",
            "Epoch 76/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0035 - val_loss: 0.0282\n",
            "Epoch 77/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0063 - val_loss: 0.0398\n",
            "Epoch 78/80\n",
            "7232/8000 [==========================>...] - ETA: 1s - loss: 0.0163"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0154 - val_loss: 0.3783\n",
            "Epoch 79/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0040 - val_loss: 0.0238\n",
            "Epoch 80/80\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0036 - val_loss: 0.0203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6958ec5208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "fAniZJVMZaXj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss=[7.5858,0.2848,0.1340,0.0840,0.0606,0.0462,0.0357,0.0296,0.0251,0.0233,0.0197,0.0181.0.0165,0.0148,0.0150,0.0130,0.0117,0.0110,0.0116,0.0089,0.00958,0.0072,0.0086,0.0064,0.0066,0.0106,0.0064,0.0082,0.0084,0.0064,0.0073,0.0066,0.0076,0.0060,0.0081, 0.0052,0.0067,0.0057,0.0068, 0.0065,0.0061,0.008,0.0041,0.0055,0.0045,0.0045, 0.0058,0.0061,0.0047,0.0047,0.0046,0.0058,0.0038,0.0038,0.0057,0.0056,0.0049,0.0051,0.003,0.0035,0.005,0.0051,0.0036,0.0046,0.0045,0.005,0.0027,0.0029,0.0042,0.0041,.0046,0.0024,0.0036,0.0035,0.0035,0.0063,0.0154,0.0040,0.0036]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upb5_UT4ph0F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(feature_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iwh1uAn6ph0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93608ecc-beba-4965-e0db-24e01aa801e3"
      },
      "cell_type": "code",
      "source": [
        "feature_model=path+\"triplet_dataset123FC_10000_triplet_weights_90nd.h5\"\n",
        "\n",
        "print(feature_model)\n",
        "model.load_weights(feature_model,'r')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./my_drive/app/triplet_dataset123FC_10000_triplet_weights_90nd.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tXvIXIUFph1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "77117513-201e-4996-b9e9-0ad37290eb88"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "anchor (InputLayer)             (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positive (InputLayer)           (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "negative (InputLayer)           (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Model)                 (None, 4096)         188752      anchor[0][0]                     \n",
            "                                                                 positive[0][0]                   \n",
            "                                                                 negative[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 12288)        0           model_3[1][0]                    \n",
            "                                                                 model_3[2][0]                    \n",
            "                                                                 model_3[3][0]                    \n",
            "==================================================================================================\n",
            "Total params: 188,752\n",
            "Trainable params: 188,064\n",
            "Non-trainable params: 688\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OPKVVk-xph14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.get_config()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8EmOYJvph2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e1b99fc5-973d-4d0b-984e-d35ed3740725"
      },
      "cell_type": "code",
      "source": [
        "model.inputs"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'anchor_2:0' shape=(?, 64, 64, 1) dtype=float32>,\n",
              " <tf.Tensor 'positive_2:0' shape=(?, 64, 64, 1) dtype=float32>,\n",
              " <tf.Tensor 'negative_2:0' shape=(?, 64, 64, 1) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "4LuvweZKph3V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for i in model.layers:\n",
        "#    print (\"Layer weights\", i)\n",
        "#    print (i.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_5UfeKeph3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd560b93-4d8a-4d2d-e079-0139b3c40cb3"
      },
      "cell_type": "code",
      "source": [
        "model.outputs"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'concatenate_2/concat:0' shape=(?, ?) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "v4Y2plLsph4b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Predict for metric network training"
      ]
    },
    {
      "metadata": {
        "id": "XGXHL8zSph4e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "in1=np.reshape(x[:,0,:,:],(data_instances,64,64,1))\n",
        "in2=np.reshape(x[:,1,:,:],(data_instances,64,64,1))\n",
        "in3=np.reshape(x[:,2,:,:],(data_instances,64,64,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLg-xLnOHbDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c3edc87a-fd44-4810-8fac-1b2746b5148d"
      },
      "cell_type": "code",
      "source": [
        "pred=model.predict([in1,in2,in3])\n",
        "print (pred[0,:])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.23270766  0.32880104  0.2328936  ...  0.3546826  -0.00057488\n",
            " -0.00056187]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5jtvG5k7ph4u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Make Metric network feasible input"
      ]
    },
    {
      "metadata": {
        "id": "ZzJr9TUlph4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcdd2f85-671d-4753-9939-97a059303cf1"
      },
      "cell_type": "code",
      "source": [
        "a=pred[:,0:4096]\n",
        "p=pred[:,4096:8192]\n",
        "n=pred[:,8192:12288]\n",
        "\n",
        "metric_a_p=np.array([np.append(a[d,:], p[d,:]) for d in range(len(a))]) \n",
        "#metric_a_p=np.array((np.concatenate((pred[:,0:4096],pred[:,4096:8192]))))\n",
        "#metric_a_n=np.array((np.concatenate((pred[:,0:4096],pred[:,8192:12288]))))\n",
        "metric_a_n=np.array([np.append(a[d,:], n[d,:]) for d in range(len(a))])\n",
        "print (metric_a_p.shape,metric_a_n.shape)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 8192) (10000, 8192)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-rHSiZmEph5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a_p=np.square(pred[:,0:4096]-pred[:,4096:8192])\n",
        "a_p=[sum(a_p[d,:]) for d in range(data_instances)]\n",
        "a_p=np.array(a_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7wc1Ntokph5S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "a_n=np.square(pred[:,0:4096]-pred[:,8192:12288])\n",
        "a_n=[sum(a_n[d,:]) for d in range(data_instances)]\n",
        "a_n=np.array(a_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "34K1pJ9oph5b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "ea8e8cef-15a1-4776-fb8a-1d65d6379fc2"
      },
      "cell_type": "code",
      "source": [
        "diff=a_p-a_n\n",
        "plt.plot(diff)\n",
        "plt.title(\"anchor_positive-anchor_negative distance\")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'anchor_positive-anchor_negative distance')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFZCAYAAADZ6SWdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6957197ba8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "G3ie8tcJph53",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Metric Part"
      ]
    },
    {
      "metadata": {
        "id": "FeJWLGSmph6B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_metric_network(input_shape):\n",
        "    '''Base network to be shared (eq. to feature extraction).\n",
        "    '''\n",
        "    print (\"entering network\")\n",
        "    input = Input(shape=input_shape)\n",
        "    print (input.shape)\n",
        "    \n",
        "    x=Dense(1024, name='first',kernel_initializer=\"glorot_normal\")(input)\n",
        "    x=BatchNormalization(momentum=0.99, epsilon=0.001, beta_initializer='zeros', gamma_initializer='ones')(x)\n",
        "    x=LeakyReLU(alpha=.001)(x)\n",
        "    print (x.shape)\n",
        "    x=Dense(512, name='second',kernel_initializer=\"glorot_normal\")(x)\n",
        "    x=BatchNormalization(momentum=0.99, epsilon=0.001, beta_initializer='zeros', gamma_initializer='ones')(x)\n",
        "    x=LeakyReLU(alpha=.001)(x)\n",
        "    print (x.shape)\n",
        "    x=Dense(1, name='third',kernel_initializer=\"glorot_normal\")(x)\n",
        "    x=BatchNormalization(momentum=0.99, epsilon=0.001, beta_initializer='zeros', gamma_initializer='ones')(x)\n",
        "    x=LeakyReLU(alpha=.001)(x)\n",
        "    print (x.shape)\n",
        "    print (\"exiting network\")\n",
        "    return Model(input, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kpttxcZtTdsF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b87dc5bd-7d1e-44f7-bffd-68e49dd0f28c"
      },
      "cell_type": "code",
      "source": [
        "in_dim=8192\n",
        "inp=(in_dim,)\n",
        "output_FC=(1,)\n",
        "metric_network=create_metric_network(inp)\n",
        "a_p=Input(shape=inp)\n",
        "a_n=Input(shape=inp)\n",
        "\n",
        "anch_pos=metric_network(a_p)\n",
        "anch_neg=metric_network(a_n)\n",
        "\n",
        "merged_vector = concatenate([anch_pos, anch_neg],axis=-1)\n",
        "prob=Dense(2, activation='softmax', name='third')(merged_vector)\n",
        "model_fc = Model(inputs=[a_p,a_n], outputs=prob)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entering network\n",
            "(?, 8192)\n",
            "(?, 1024)\n",
            "(?, 512)\n",
            "(?, 1)\n",
            "exiting network\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7UdUP7Bpph6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2885
        },
        "outputId": "9db99746-8be9-4e88-aa6a-195f61c30513"
      },
      "cell_type": "code",
      "source": [
        "model_fc.compile(optimizer=Adam(lr=learning_rate),\n",
        "              loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
        "#sys.exit(0)\n",
        "y_true=np.array([np.ones((data_instances)),np.zeros((data_instances))])\n",
        "label=y_true.T\n",
        "\n",
        "print (label.shape)\n",
        "metric_a_p=np.reshape((metric_a_p),(len(metric_a_p),in_dim))\n",
        "print (metric_a_p.shape)\n",
        "metric_a_n=np.reshape((metric_a_n),(len(metric_a_n),in_dim))\n",
        "# Training the model\n",
        "model_fc.fit([metric_a_p,metric_a_n],[label] ,validation_split=0.2,batch_size=64, epochs=epoch)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 2)\n",
            "(10000, 8192)\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/80\n",
            "8000/8000 [==============================] - 8s 988us/step - loss: 0.6422 - acc: 0.7496 - val_loss: 0.6066 - val_acc: 0.7380\n",
            "Epoch 2/80\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 0.4513 - acc: 0.9749 - val_loss: 0.4954 - val_acc: 1.0000\n",
            "Epoch 3/80\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 0.3421 - acc: 0.9954 - val_loss: 0.4298 - val_acc: 1.0000\n",
            "Epoch 4/80\n",
            "7488/8000 [===========================>..] - ETA: 0s - loss: 0.2687 - acc: 0.9991"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 545us/step - loss: 0.2670 - acc: 0.9991 - val_loss: 0.3738 - val_acc: 1.0000\n",
            "Epoch 5/80\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 0.2126 - acc: 1.0000 - val_loss: 0.3071 - val_acc: 1.0000\n",
            "Epoch 6/80\n",
            "8000/8000 [==============================] - 4s 541us/step - loss: 0.1718 - acc: 1.0000 - val_loss: 0.2959 - val_acc: 1.0000\n",
            "Epoch 7/80\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 0.1393 - acc: 1.0000 - val_loss: 0.2547 - val_acc: 1.0000\n",
            "Epoch 8/80\n",
            "6080/8000 [=====================>........] - ETA: 0s - loss: 0.1148 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 543us/step - loss: 0.1123 - acc: 1.0000 - val_loss: 0.2432 - val_acc: 1.0000\n",
            "Epoch 9/80\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 0.0919 - acc: 0.9999 - val_loss: 0.2235 - val_acc: 1.0000\n",
            "Epoch 10/80\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 0.0736 - acc: 1.0000 - val_loss: 0.1998 - val_acc: 0.9945\n",
            "Epoch 11/80\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 0.0578 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 1.0000\n",
            "Epoch 12/80\n",
            "5568/8000 [===================>..........] - ETA: 1s - loss: 0.0475 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 541us/step - loss: 0.0461 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
            "Epoch 13/80\n",
            "8000/8000 [==============================] - 4s 545us/step - loss: 0.0361 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
            "Epoch 14/80\n",
            "8000/8000 [==============================] - 4s 540us/step - loss: 0.0287 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 1.0000\n",
            "Epoch 15/80\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 1.0000\n",
            "Epoch 16/80\n",
            "5440/8000 [===================>..........] - ETA: 1s - loss: 0.0204 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 543us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
            "Epoch 17/80\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 1.0000\n",
            "Epoch 18/80\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 1.0000\n",
            "Epoch 19/80\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1579 - val_acc: 1.0000\n",
            "Epoch 20/80\n",
            "5184/8000 [==================>...........] - ETA: 1s - loss: 0.0112 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 546us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0677 - val_acc: 1.0000\n",
            "Epoch 21/80\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.6398e-04 - val_acc: 1.0000\n",
            "Epoch 22/80\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 23/80\n",
            "8000/8000 [==============================] - 4s 546us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.8439e-04 - val_acc: 1.0000\n",
            "Epoch 24/80\n",
            "4800/8000 [=================>............] - ETA: 1s - loss: 0.0037 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 549us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 25/80\n",
            "8000/8000 [==============================] - 4s 541us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
            "Epoch 26/80\n",
            "8000/8000 [==============================] - 4s 541us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0447 - val_acc: 1.0000\n",
            "Epoch 27/80\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 28/80\n",
            "5184/8000 [==================>...........] - ETA: 1s - loss: 0.0015 - acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 545us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
            "Epoch 29/80\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1476 - val_acc: 1.0000\n",
            "Epoch 30/80\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 31/80\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 9.9096e-04 - acc: 1.0000 - val_loss: 7.5833e-04 - val_acc: 1.0000\n",
            "Epoch 32/80\n",
            "5568/8000 [===================>..........] - ETA: 1s - loss: 0.0012 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 546us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
            "Epoch 33/80\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 9.2621e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
            "Epoch 34/80\n",
            "8000/8000 [==============================] - 4s 553us/step - loss: 7.5751e-04 - acc: 1.0000 - val_loss: 9.5641e-05 - val_acc: 1.0000\n",
            "Epoch 35/80\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 7.0995e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
            "Epoch 36/80\n",
            "4672/8000 [================>.............] - ETA: 1s - loss: 5.3279e-04 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 547us/step - loss: 4.7727e-04 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
            "Epoch 37/80\n",
            "8000/8000 [==============================] - 4s 552us/step - loss: 3.7760e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 38/80\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 4.7247e-04 - acc: 1.0000 - val_loss: 1.0099e-04 - val_acc: 1.0000\n",
            "Epoch 39/80\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 4.8216e-04 - acc: 1.0000 - val_loss: 6.7171e-05 - val_acc: 1.0000\n",
            "Epoch 40/80\n",
            "4672/8000 [================>.............] - ETA: 1s - loss: 4.1217e-04 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 546us/step - loss: 3.6591e-04 - acc: 1.0000 - val_loss: 7.0147e-04 - val_acc: 1.0000\n",
            "Epoch 41/80\n",
            "8000/8000 [==============================] - 4s 541us/step - loss: 3.5179e-04 - acc: 1.0000 - val_loss: 3.5260e-04 - val_acc: 1.0000\n",
            "Epoch 42/80\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 2.9624e-04 - acc: 1.0000 - val_loss: 4.8602e-04 - val_acc: 1.0000\n",
            "Epoch 43/80\n",
            "8000/8000 [==============================] - 4s 545us/step - loss: 2.3204e-04 - acc: 1.0000 - val_loss: 4.0140e-04 - val_acc: 1.0000\n",
            "Epoch 44/80\n",
            "4160/8000 [==============>...............] - ETA: 1s - loss: 1.9509e-04 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 546us/step - loss: 1.9196e-04 - acc: 1.0000 - val_loss: 3.3097e-04 - val_acc: 1.0000\n",
            "Epoch 45/80\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 4.2504e-04 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
            "Epoch 46/80\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 3.8251e-04 - acc: 1.0000 - val_loss: 7.0865e-04 - val_acc: 1.0000\n",
            "Epoch 47/80\n",
            "8000/8000 [==============================] - 4s 542us/step - loss: 2.3033e-04 - acc: 1.0000 - val_loss: 0.1519 - val_acc: 1.0000\n",
            "Epoch 48/80\n",
            "3648/8000 [============>.................] - ETA: 2s - loss: 1.8598e-04 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 548us/step - loss: 1.4891e-04 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
            "Epoch 49/80\n",
            "8000/8000 [==============================] - 4s 549us/step - loss: 1.2166e-04 - acc: 1.0000 - val_loss: 0.1230 - val_acc: 1.0000\n",
            "Epoch 50/80\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 1.3796e-04 - acc: 1.0000 - val_loss: 2.3964e-04 - val_acc: 1.0000\n",
            "Epoch 51/80\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 1.0392e-04 - acc: 1.0000 - val_loss: 1.3668e-04 - val_acc: 1.0000\n",
            "Epoch 52/80\n",
            "4288/8000 [===============>..............] - ETA: 1s - loss: 1.0993e-04 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 539us/step - loss: 1.4708e-04 - acc: 1.0000 - val_loss: 1.5725e-05 - val_acc: 1.0000\n",
            "Epoch 53/80\n",
            "8000/8000 [==============================] - 4s 542us/step - loss: 8.8891e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
            "Epoch 54/80\n",
            "8000/8000 [==============================] - 4s 545us/step - loss: 2.6671e-04 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
            "Epoch 55/80\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 3.8513e-04 - acc: 1.0000 - val_loss: 2.1464e-05 - val_acc: 1.0000\n",
            "Epoch 56/80\n",
            "4544/8000 [================>.............] - ETA: 1s - loss: 1.4396e-04 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 538us/step - loss: 1.4489e-04 - acc: 1.0000 - val_loss: 3.3176e-04 - val_acc: 1.0000\n",
            "Epoch 57/80\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 1.2737e-04 - acc: 1.0000 - val_loss: 8.1624e-05 - val_acc: 1.0000\n",
            "Epoch 58/80\n",
            "8000/8000 [==============================] - 4s 545us/step - loss: 1.2527e-04 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 59/80\n",
            "8000/8000 [==============================] - 4s 547us/step - loss: 9.1206e-05 - acc: 1.0000 - val_loss: 4.5400e-04 - val_acc: 1.0000\n",
            "Epoch 60/80\n",
            "4416/8000 [===============>..............] - ETA: 1s - loss: 3.5654e-04 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 546us/step - loss: 2.8871e-04 - acc: 1.0000 - val_loss: 0.0913 - val_acc: 1.0000\n",
            "Epoch 61/80\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 9.2903e-05 - acc: 1.0000 - val_loss: 2.4629e-04 - val_acc: 1.0000\n",
            "Epoch 62/80\n",
            "8000/8000 [==============================] - 4s 546us/step - loss: 2.7303e-04 - acc: 1.0000 - val_loss: 0.1205 - val_acc: 1.0000\n",
            "Epoch 63/80\n",
            "8000/8000 [==============================] - 4s 541us/step - loss: 1.6914e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 64/80\n",
            "4544/8000 [================>.............] - ETA: 1s - loss: 1.8285e-04 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 543us/step - loss: 1.7561e-04 - acc: 1.0000 - val_loss: 5.1923e-06 - val_acc: 1.0000\n",
            "Epoch 65/80\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 5.1154e-05 - acc: 1.0000 - val_loss: 1.9009e-04 - val_acc: 1.0000\n",
            "Epoch 66/80\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 7.3233e-05 - acc: 1.0000 - val_loss: 7.6447e-05 - val_acc: 1.0000\n",
            "Epoch 67/80\n",
            "8000/8000 [==============================] - 4s 550us/step - loss: 4.5744e-05 - acc: 1.0000 - val_loss: 6.1520e-04 - val_acc: 1.0000\n",
            "Epoch 68/80\n",
            "3776/8000 [=============>................] - ETA: 2s - loss: 3.8097e-05 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 549us/step - loss: 4.1818e-05 - acc: 1.0000 - val_loss: 2.1391e-04 - val_acc: 1.0000\n",
            "Epoch 69/80\n",
            "8000/8000 [==============================] - 4s 548us/step - loss: 1.0820e-04 - acc: 1.0000 - val_loss: 2.9428e-04 - val_acc: 1.0000\n",
            "Epoch 70/80\n",
            "8000/8000 [==============================] - 4s 536us/step - loss: 2.1394e-05 - acc: 1.0000 - val_loss: 6.4654e-05 - val_acc: 1.0000\n",
            "Epoch 71/80\n",
            "8000/8000 [==============================] - 4s 537us/step - loss: 2.0691e-05 - acc: 1.0000 - val_loss: 9.3646e-05 - val_acc: 1.0000\n",
            "Epoch 72/80\n",
            "4288/8000 [===============>..............] - ETA: 1s - loss: 1.7566e-05 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 541us/step - loss: 1.6191e-05 - acc: 1.0000 - val_loss: 1.9598e-04 - val_acc: 1.0000\n",
            "Epoch 73/80\n",
            "8000/8000 [==============================] - 4s 545us/step - loss: 2.9991e-05 - acc: 1.0000 - val_loss: 0.0559 - val_acc: 1.0000\n",
            "Epoch 74/80\n",
            "8000/8000 [==============================] - 4s 546us/step - loss: 1.4423e-05 - acc: 1.0000 - val_loss: 4.2628e-04 - val_acc: 1.0000\n",
            "Epoch 75/80\n",
            "8000/8000 [==============================] - 4s 543us/step - loss: 2.4347e-05 - acc: 1.0000 - val_loss: 0.1182 - val_acc: 1.0000\n",
            "Epoch 76/80\n",
            "4160/8000 [==============>...............] - ETA: 1s - loss: 2.6386e-05 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 547us/step - loss: 1.8764e-05 - acc: 1.0000 - val_loss: 3.2759e-05 - val_acc: 1.0000\n",
            "Epoch 77/80\n",
            "8000/8000 [==============================] - 4s 542us/step - loss: 1.0799e-05 - acc: 1.0000 - val_loss: 9.9356e-05 - val_acc: 1.0000\n",
            "Epoch 78/80\n",
            "8000/8000 [==============================] - 4s 544us/step - loss: 1.3069e-05 - acc: 1.0000 - val_loss: 7.1281e-06 - val_acc: 1.0000\n",
            "Epoch 79/80\n",
            "8000/8000 [==============================] - 4s 540us/step - loss: 2.6478e-05 - acc: 1.0000 - val_loss: 2.1790e-04 - val_acc: 1.0000\n",
            "Epoch 80/80\n",
            "4672/8000 [================>.............] - ETA: 1s - loss: 7.9696e-06 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 4s 542us/step - loss: 1.0663e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6956a11e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "metadata": {
        "id": "XbwfBWmfph6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model_fc.save_weights(FC_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oCLtngZEph6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_fc.load_weights(FC_model,'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SSvuPmGqph6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f943fe60-5015-4989-e2ad-6d4b845d1ca5"
      },
      "cell_type": "code",
      "source": [
        "test_x=load_data(path+\"test_triplet_dataset\")\n",
        "#x=np.array(x,dtype=np.uint8)\n",
        "#data_instances=len(x)\n",
        "print (test_x.shape)\n",
        "test_instances=len(test_x)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(858, 3, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-tjTXLrwph7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cd2445d4-cf0d-4c94-f5ad-822bc72ad457"
      },
      "cell_type": "code",
      "source": [
        "in1=np.reshape(test_x[:,0,:,:,0],(test_instances,64,64,1))\n",
        "in2=np.reshape(test_x[:,1,:,:,0],(test_instances,64,64,1))\n",
        "in3=np.reshape(test_x[:,2,:,:,0],(test_instances,64,64,1))\n",
        "pred=model.predict([in1,in2,in3])\n",
        "print (pred.shape)\n",
        "#metric_a_p=np.array((np.concatenate((pred[:,0:4096],pred[:,0:4096]))))\n",
        "#metric_a_n=np.array((np.concatenate((pred[:,4096:8192],pred[:,8192:12288]))))\n",
        "#print (metric_a_p.shape,metric_a_n.shape)\n",
        "a=pred[:,0:4096]\n",
        "p=pred[:,4096:8192]\n",
        "n=pred[:,8192:12288]\n",
        "metric_a_p=np.array([np.append(a[d,:], p[d,:]) for d in range(len(a))]) \n",
        "#metric_a_p=np.array((np.concatenate((pred[:,0:4096],pred[:,4096:8192]))))\n",
        "#metric_a_n=np.array((np.concatenate((pred[:,0:4096],pred[:,8192:12288]))))\n",
        "metric_a_n=np.array([np.append(a[d,:], n[d,:]) for d in range(len(a))])\n",
        "print (metric_a_p.shape,metric_a_n.shape)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(858, 12288)\n",
            "(858, 8192) (858, 8192)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QSUsxEhAph7U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d086bb04-2765-48b8-a452-4f82cc8a8f17"
      },
      "cell_type": "code",
      "source": [
        "model_fc.inputs"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'input_18:0' shape=(?, 8192) dtype=float32>,\n",
              " <tf.Tensor 'input_19:0' shape=(?, 8192) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "metadata": {
        "id": "44c5XBqCph77",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#with open(path+name+\"FC_10000_triplet_weights_nd.json\", 'r') as f:\n",
        "#    model_fc=model_from_json(f.read())\n",
        "#model_fc.load_weights(path+name+\"FC_10000_triplet_weights_nd.h5\",'r')\n",
        "#model_fc.inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8HZr1WL3ph8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e9d7c2a2-9294-4388-8b43-00ae3fa3ac46"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "pred=model_fc.predict([metric_a_p,metric_a_n])\n",
        "\n",
        "print (pred)\n",
        "#print (pred[:,1])\n",
        "print(label[1715,0])\n",
        "print(len(pred))\n",
        "count_positive = 0;\n",
        "count_negative = 0;\n",
        "for l in range(0,858):\n",
        "  #print(label[l])\n",
        "  if pred[l,0] > pred[l,1]:\n",
        "     count_positive = count_positive + 1;\n",
        "\n",
        "      \n",
        "print(count_positive)\n",
        "\n",
        "  \n",
        "#print(metric_a_p)\n",
        "#print(metric_a_n)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9999630e-01 3.7288291e-06]\n",
            " [9.9999964e-01 4.1235151e-07]\n",
            " [9.9999917e-01 8.1361310e-07]\n",
            " ...\n",
            " [9.9999535e-01 4.6865948e-06]\n",
            " [9.9999750e-01 2.5115605e-06]\n",
            " [9.9998617e-01 1.3826318e-05]]\n",
            "1.0\n",
            "858\n",
            "858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EX9a-dYVvt-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KDE27AwLtE5f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33c96322-219e-4c07-a72b-f66fae1aa1b8"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "score=precision_recall_fscore_support((label[0:858,0]), pred[0:858,0].round(), average='macro')\n",
        "#precision_recall_fscore_support((label[858:1715,1]), pred[858:1715,1].round(), average='macro')\n",
        "#print(label[858:1715,1])\n",
        "#print( pred[858:1715,1])\n",
        "#print( pred[0:858,0])\n",
        "print (score)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1.0, 1.0, 1.0, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qOE5befiIMEA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "HXvvdPAc1Zuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92974337-f4bf-49ee-fed1-f1abfe245328"
      },
      "cell_type": "code",
      "source": [
        "test_x=load_data(path+\"triplet_dataset\")\n",
        "#x=np.array(x,dtype=np.uint8)\n",
        "#data_instances=len(x)\n",
        "print (test_x.shape)\n",
        "test_instances=len(test_x)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(468, 3, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A6cRReVF4GIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fc4aec10-9566-4d49-871a-c6e2b142087f"
      },
      "cell_type": "code",
      "source": [
        "in1=np.reshape(test_x[:,0,:,:,0],(test_instances,64,64,1))\n",
        "in2=np.reshape(test_x[:,1,:,:,0],(test_instances,64,64,1))\n",
        "in3=np.reshape(test_x[:,2,:,:,0],(test_instances,64,64,1))\n",
        "pred=model.predict([in1,in2,in3])\n",
        "print (pred.shape)\n",
        "#metric_a_p=np.array((np.concatenate((pred[:,0:4096],pred[:,0:4096]))))\n",
        "#metric_a_n=np.array((np.concatenate((pred[:,4096:8192],pred[:,8192:12288]))))\n",
        "#print (metric_a_p.shape,metric_a_n.shape)\n",
        "a=pred[:,0:4096]\n",
        "p=pred[:,4096:8192]\n",
        "n=pred[:,8192:12288]\n",
        "metric_a_p=np.array([np.append(a[d,:], p[d,:]) for d in range(len(a))]) \n",
        "#metric_a_p=np.array((np.concatenate((pred[:,0:4096],pred[:,4096:8192]))))\n",
        "#metric_a_n=np.array((np.concatenate((pred[:,0:4096],pred[:,8192:12288]))))\n",
        "metric_a_n=np.array([np.append(a[d,:], n[d,:]) for d in range(len(a))])\n",
        "print (metric_a_p.shape,metric_a_n.shape)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(468, 12288)\n",
            "(468, 8192) (468, 8192)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ASlHngCw4PXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8197
        },
        "outputId": "c309eabc-6d9b-45e5-f807-145daea19062"
      },
      "cell_type": "code",
      "source": [
        "pred=model_fc.predict([metric_a_p,metric_a_n])\n",
        "\n",
        "print (pred)\n",
        "#print (pred[:,1])\n",
        "print(label[1715,0])\n",
        "print(len(pred))\n",
        "count_positive = 0;\n",
        "count_negative = 0;\n",
        "for l in range(0,468):\n",
        "  #print(label[l])\n",
        "  if pred[l,0] > pred[l,1]:\n",
        "     count_positive = count_positive + 1;\n",
        "\n",
        "      \n",
        "print(count_positive)\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.99994755e-01 5.27340899e-06]\n",
            " [9.99999523e-01 4.82669179e-07]\n",
            " [9.99999404e-01 5.38254994e-07]\n",
            " [9.99999046e-01 9.10261917e-07]\n",
            " [9.99999046e-01 9.49540492e-07]\n",
            " [9.99967456e-01 3.25420224e-05]\n",
            " [9.99999523e-01 4.39139711e-07]\n",
            " [9.99999404e-01 5.57048509e-07]\n",
            " [9.99999523e-01 4.34154828e-07]\n",
            " [9.99999523e-01 4.64303241e-07]\n",
            " [9.99999523e-01 4.55669436e-07]\n",
            " [9.99997973e-01 1.99425608e-06]\n",
            " [9.99978304e-01 2.17291217e-05]\n",
            " [9.99998689e-01 1.35027665e-06]\n",
            " [9.99999523e-01 4.82977669e-07]\n",
            " [9.99999523e-01 4.86321198e-07]\n",
            " [9.99999642e-01 3.83396156e-07]\n",
            " [9.99996543e-01 3.41505779e-06]\n",
            " [9.99995589e-01 4.39857013e-06]\n",
            " [9.99999166e-01 8.31784234e-07]\n",
            " [9.99996781e-01 3.20737968e-06]\n",
            " [9.99991894e-01 8.12149483e-06]\n",
            " [9.99993324e-01 6.63636001e-06]\n",
            " [9.99998450e-01 1.49395851e-06]\n",
            " [9.99999404e-01 5.76920627e-07]\n",
            " [9.99980211e-01 1.98375656e-05]\n",
            " [9.99993682e-01 6.37045787e-06]\n",
            " [9.99983788e-01 1.61837233e-05]\n",
            " [9.99985218e-01 1.47741075e-05]\n",
            " [9.99994040e-01 6.00252724e-06]\n",
            " [9.99989986e-01 1.00722318e-05]\n",
            " [9.99989629e-01 1.04298624e-05]\n",
            " [9.99975204e-01 2.47947319e-05]\n",
            " [9.99990821e-01 9.17481520e-06]\n",
            " [9.99989271e-01 1.07002434e-05]\n",
            " [9.99999523e-01 4.23800856e-07]\n",
            " [9.99990106e-01 9.86472878e-06]\n",
            " [9.99995112e-01 4.92225536e-06]\n",
            " [9.99999285e-01 7.32798583e-07]\n",
            " [9.99990225e-01 9.82166057e-06]\n",
            " [9.99998927e-01 1.04838045e-06]\n",
            " [9.99992251e-01 7.73826469e-06]\n",
            " [9.99988914e-01 1.10434603e-05]\n",
            " [9.99995351e-01 4.67975269e-06]\n",
            " [9.99999642e-01 3.45334570e-07]\n",
            " [9.99999523e-01 4.82337384e-07]\n",
            " [9.99990463e-01 9.56887106e-06]\n",
            " [9.99995589e-01 4.39503947e-06]\n",
            " [9.99999523e-01 5.36209313e-07]\n",
            " [9.99999404e-01 6.52686424e-07]\n",
            " [9.99996543e-01 3.46470438e-06]\n",
            " [9.99999404e-01 5.49768572e-07]\n",
            " [9.99981880e-01 1.81753494e-05]\n",
            " [9.99998450e-01 1.58277703e-06]\n",
            " [9.99998331e-01 1.64767607e-06]\n",
            " [9.99999523e-01 4.90133573e-07]\n",
            " [9.99999523e-01 4.94637732e-07]\n",
            " [9.99991655e-01 8.28884095e-06]\n",
            " [9.99998927e-01 1.12515784e-06]\n",
            " [9.99989152e-01 1.08546392e-05]\n",
            " [9.99999046e-01 9.99896770e-07]\n",
            " [9.99998927e-01 1.06856760e-06]\n",
            " [9.99992609e-01 7.35183130e-06]\n",
            " [9.99999285e-01 6.81994720e-07]\n",
            " [9.99999523e-01 4.79884534e-07]\n",
            " [9.99999285e-01 6.78920742e-07]\n",
            " [9.99999404e-01 6.06645870e-07]\n",
            " [9.99999523e-01 5.26394047e-07]\n",
            " [9.99998331e-01 1.72792591e-06]\n",
            " [9.99999285e-01 7.08505922e-07]\n",
            " [9.99992371e-01 7.58833448e-06]\n",
            " [9.99995232e-01 4.75730212e-06]\n",
            " [9.99996901e-01 3.07414666e-06]\n",
            " [9.99995112e-01 4.86624140e-06]\n",
            " [9.99998450e-01 1.57792556e-06]\n",
            " [9.99999404e-01 6.32839487e-07]\n",
            " [9.99999166e-01 8.25590689e-07]\n",
            " [9.99999523e-01 5.00755789e-07]\n",
            " [9.99992132e-01 7.81668496e-06]\n",
            " [9.99999285e-01 6.75043225e-07]\n",
            " [9.99999523e-01 5.30670377e-07]\n",
            " [9.99412775e-01 5.87281596e-04]\n",
            " [9.99998927e-01 1.05900801e-06]\n",
            " [9.99997735e-01 2.24704172e-06]\n",
            " [9.99999404e-01 5.37227834e-07]\n",
            " [9.99999285e-01 7.61976764e-07]\n",
            " [9.99993443e-01 6.49858703e-06]\n",
            " [9.99999404e-01 5.71519479e-07]\n",
            " [9.99997139e-01 2.83762279e-06]\n",
            " [9.99999166e-01 8.20646051e-07]\n",
            " [9.99999285e-01 7.33248783e-07]\n",
            " [9.99999285e-01 7.20479818e-07]\n",
            " [9.99997497e-01 2.52652217e-06]\n",
            " [9.99999642e-01 3.85883936e-07]\n",
            " [9.99999881e-01 6.91175330e-08]\n",
            " [9.99996781e-01 3.20335675e-06]\n",
            " [9.99999166e-01 8.51714901e-07]\n",
            " [9.99998093e-01 1.90812625e-06]\n",
            " [9.99996543e-01 3.46516686e-06]\n",
            " [9.99997258e-01 2.71867066e-06]\n",
            " [9.99999285e-01 7.22819721e-07]\n",
            " [9.99998808e-01 1.22321808e-06]\n",
            " [9.99999166e-01 8.15401279e-07]\n",
            " [9.99998689e-01 1.30165938e-06]\n",
            " [9.99705493e-01 2.94514844e-04]\n",
            " [9.99999404e-01 5.81868164e-07]\n",
            " [9.99999285e-01 7.45866203e-07]\n",
            " [9.99999166e-01 8.89598198e-07]\n",
            " [9.99998689e-01 1.28810893e-06]\n",
            " [9.99997973e-01 2.00299519e-06]\n",
            " [9.99994159e-01 5.85999715e-06]\n",
            " [9.99999046e-01 9.24126539e-07]\n",
            " [9.99999166e-01 7.81383790e-07]\n",
            " [9.99993801e-01 6.24410995e-06]\n",
            " [9.99990582e-01 9.38513585e-06]\n",
            " [9.99997258e-01 2.73936621e-06]\n",
            " [9.99998689e-01 1.36580900e-06]\n",
            " [9.99998331e-01 1.71913541e-06]\n",
            " [9.99998689e-01 1.27228634e-06]\n",
            " [9.99999404e-01 6.43177486e-07]\n",
            " [9.99996901e-01 3.04479431e-06]\n",
            " [9.99995947e-01 4.07089328e-06]\n",
            " [9.99999642e-01 4.14614163e-07]\n",
            " [9.99998569e-01 1.46521108e-06]\n",
            " [9.99999285e-01 6.76453169e-07]\n",
            " [9.99998093e-01 1.91298750e-06]\n",
            " [9.99999046e-01 9.25476797e-07]\n",
            " [9.99998927e-01 1.02504350e-06]\n",
            " [9.99997854e-01 2.08720712e-06]\n",
            " [9.99998927e-01 1.12597149e-06]\n",
            " [9.99998450e-01 1.60674892e-06]\n",
            " [9.99997497e-01 2.46345735e-06]\n",
            " [9.99997377e-01 2.56437124e-06]\n",
            " [9.99998689e-01 1.36682149e-06]\n",
            " [9.99998927e-01 1.02158788e-06]\n",
            " [9.99993205e-01 6.83408325e-06]\n",
            " [9.99999166e-01 8.81672406e-07]\n",
            " [9.99999285e-01 7.34539412e-07]\n",
            " [9.99997258e-01 2.76987089e-06]\n",
            " [9.99998808e-01 1.18640708e-06]\n",
            " [9.99997020e-01 2.99991484e-06]\n",
            " [9.99999404e-01 5.93233551e-07]\n",
            " [9.99997020e-01 2.97043266e-06]\n",
            " [9.99999285e-01 6.71397117e-07]\n",
            " [9.99998569e-01 1.48640947e-06]\n",
            " [9.99997973e-01 2.00638283e-06]\n",
            " [9.99998212e-01 1.74702552e-06]\n",
            " [9.99997973e-01 2.02015303e-06]\n",
            " [9.99999404e-01 6.14483838e-07]\n",
            " [9.99998450e-01 1.56467900e-06]\n",
            " [9.99999523e-01 5.10251596e-07]\n",
            " [9.99999523e-01 5.14340854e-07]\n",
            " [9.99999046e-01 9.45264219e-07]\n",
            " [9.99999166e-01 7.97367477e-07]\n",
            " [9.99998450e-01 1.53849453e-06]\n",
            " [9.99997616e-01 2.42604256e-06]\n",
            " [9.99997616e-01 2.39208180e-06]\n",
            " [9.99999881e-01 6.66258089e-08]\n",
            " [9.99998212e-01 1.82720919e-06]\n",
            " [9.99997616e-01 2.35110474e-06]\n",
            " [9.99999166e-01 8.15735746e-07]\n",
            " [9.99998808e-01 1.23944540e-06]\n",
            " [9.99996305e-01 3.71038323e-06]\n",
            " [9.99999166e-01 8.70057079e-07]\n",
            " [9.99996305e-01 3.64991683e-06]\n",
            " [9.99997020e-01 2.97075280e-06]\n",
            " [9.99998689e-01 1.27702833e-06]\n",
            " [9.99997020e-01 2.93289622e-06]\n",
            " [9.99998331e-01 1.68636359e-06]\n",
            " [9.99998808e-01 1.21474466e-06]\n",
            " [9.99999642e-01 3.95426184e-07]\n",
            " [9.99997973e-01 2.07837434e-06]\n",
            " [9.99985099e-01 1.48621730e-05]\n",
            " [9.99999642e-01 3.95644946e-07]\n",
            " [9.99999762e-01 2.91416939e-07]\n",
            " [9.99998689e-01 1.33920162e-06]\n",
            " [9.99998808e-01 1.21646258e-06]\n",
            " [9.99999762e-01 1.84269098e-07]\n",
            " [9.99990344e-01 9.62830563e-06]\n",
            " [9.99976754e-01 2.31989798e-05]\n",
            " [9.99998450e-01 1.53778456e-06]\n",
            " [9.99999523e-01 4.66102250e-07]\n",
            " [9.99990463e-01 9.53163726e-06]\n",
            " [9.99999642e-01 3.07513289e-07]\n",
            " [9.99999762e-01 2.50394294e-07]\n",
            " [9.99998927e-01 1.10455358e-06]\n",
            " [9.99997377e-01 2.64358414e-06]\n",
            " [9.99999642e-01 3.55618425e-07]\n",
            " [9.99999523e-01 5.03538104e-07]\n",
            " [9.99998927e-01 1.07542030e-06]\n",
            " [9.99998808e-01 1.15353305e-06]\n",
            " [9.99999166e-01 7.98066651e-07]\n",
            " [9.99990463e-01 9.48573415e-06]\n",
            " [9.99991179e-01 8.81980304e-06]\n",
            " [9.99999285e-01 7.31629655e-07]\n",
            " [9.99999166e-01 8.42796226e-07]\n",
            " [9.99998689e-01 1.29162947e-06]\n",
            " [9.99999523e-01 5.21842537e-07]\n",
            " [9.99999285e-01 7.26753399e-07]\n",
            " [9.99995112e-01 4.88781734e-06]\n",
            " [9.99988198e-01 1.18406997e-05]\n",
            " [9.99999404e-01 6.18100216e-07]\n",
            " [9.99998569e-01 1.38980033e-06]\n",
            " [9.99999523e-01 4.44415747e-07]\n",
            " [9.99999285e-01 7.13546797e-07]\n",
            " [9.99998569e-01 1.37675352e-06]\n",
            " [9.99992490e-01 7.55004066e-06]\n",
            " [9.99999046e-01 9.72505177e-07]\n",
            " [9.99999166e-01 8.42315671e-07]\n",
            " [9.99999523e-01 4.71704055e-07]\n",
            " [9.99999642e-01 4.04084489e-07]\n",
            " [9.99999046e-01 9.80860136e-07]\n",
            " [9.99999523e-01 4.50335818e-07]\n",
            " [9.99999285e-01 7.34441983e-07]\n",
            " [9.99999523e-01 4.88155706e-07]\n",
            " [9.99999523e-01 4.97134749e-07]\n",
            " [9.99998808e-01 1.16717615e-06]\n",
            " [9.99998927e-01 1.07390144e-06]\n",
            " [9.99999404e-01 5.59228226e-07]\n",
            " [9.99998927e-01 1.07933806e-06]\n",
            " [9.99998808e-01 1.24782582e-06]\n",
            " [9.99998093e-01 1.86684383e-06]\n",
            " [9.99998808e-01 1.23426594e-06]\n",
            " [9.99999523e-01 5.04846469e-07]\n",
            " [9.99999523e-01 4.36975284e-07]\n",
            " [9.99999285e-01 7.52970266e-07]\n",
            " [9.99997497e-01 2.47046341e-06]\n",
            " [9.99999523e-01 4.23345199e-07]\n",
            " [9.99999166e-01 8.39380732e-07]\n",
            " [9.99999404e-01 6.20641231e-07]\n",
            " [9.99996066e-01 3.91561252e-06]\n",
            " [9.99998808e-01 1.18905768e-06]\n",
            " [9.99999166e-01 7.84718054e-07]\n",
            " [9.99999404e-01 6.04799652e-07]\n",
            " [9.99999404e-01 5.65060986e-07]\n",
            " [9.99999404e-01 5.88351554e-07]\n",
            " [9.99995232e-01 4.78765105e-06]\n",
            " [9.99999523e-01 4.43617097e-07]\n",
            " [9.99999642e-01 4.07169068e-07]\n",
            " [9.99999285e-01 6.81921222e-07]\n",
            " [9.99999404e-01 6.10135828e-07]\n",
            " [9.99997377e-01 2.62871617e-06]\n",
            " [9.99991298e-01 8.65709444e-06]\n",
            " [9.99999523e-01 5.32525348e-07]\n",
            " [9.99997854e-01 2.11512020e-06]\n",
            " [9.99995708e-01 4.30125328e-06]\n",
            " [9.99999285e-01 6.56312238e-07]\n",
            " [9.99999166e-01 8.63790206e-07]\n",
            " [9.99999642e-01 4.04506665e-07]\n",
            " [9.99999523e-01 5.27034501e-07]\n",
            " [9.99998093e-01 1.92134507e-06]\n",
            " [9.99995828e-01 4.22298626e-06]\n",
            " [9.99998927e-01 1.07518042e-06]\n",
            " [9.99999046e-01 9.92001105e-07]\n",
            " [9.99999285e-01 7.60732291e-07]\n",
            " [9.99684691e-01 3.15345213e-04]\n",
            " [9.99999404e-01 6.33053730e-07]\n",
            " [9.99996543e-01 3.42512953e-06]\n",
            " [9.99998808e-01 1.16470892e-06]\n",
            " [9.99999404e-01 5.52631889e-07]\n",
            " [9.99999285e-01 7.36393815e-07]\n",
            " [9.99999285e-01 6.91090236e-07]\n",
            " [9.99999285e-01 7.29263888e-07]\n",
            " [9.99999523e-01 4.67049574e-07]\n",
            " [9.99998808e-01 1.15175442e-06]\n",
            " [9.99994636e-01 5.35617710e-06]\n",
            " [9.99999404e-01 5.52136669e-07]\n",
            " [9.99999523e-01 5.34051082e-07]\n",
            " [9.99998808e-01 1.24318149e-06]\n",
            " [9.99999523e-01 4.90719174e-07]\n",
            " [9.99992013e-01 7.94816606e-06]\n",
            " [9.99998212e-01 1.80775851e-06]\n",
            " [9.99999404e-01 6.46893568e-07]\n",
            " [9.99999881e-01 1.52059954e-07]\n",
            " [9.99996305e-01 3.63960726e-06]\n",
            " [9.99999285e-01 7.59204511e-07]\n",
            " [9.99999642e-01 3.12783982e-07]\n",
            " [9.99998450e-01 1.52621908e-06]\n",
            " [9.99999404e-01 5.96873463e-07]\n",
            " [9.99988556e-01 1.14320974e-05]\n",
            " [9.99998927e-01 1.13240480e-06]\n",
            " [9.99999285e-01 7.19213233e-07]\n",
            " [9.99999166e-01 8.76170418e-07]\n",
            " [9.99997020e-01 2.93798257e-06]\n",
            " [9.99999166e-01 8.58818282e-07]\n",
            " [9.99999523e-01 4.54802887e-07]\n",
            " [9.99999285e-01 7.61232286e-07]\n",
            " [9.99998808e-01 1.18269622e-06]\n",
            " [9.99998808e-01 1.14574868e-06]\n",
            " [9.99995947e-01 4.10220719e-06]\n",
            " [9.99999642e-01 3.97088883e-07]\n",
            " [9.99999523e-01 5.31583566e-07]\n",
            " [9.99999046e-01 1.01074397e-06]\n",
            " [9.99999404e-01 6.36959783e-07]\n",
            " [9.99998689e-01 1.27571741e-06]\n",
            " [9.99994516e-01 5.44419845e-06]\n",
            " [9.99999762e-01 2.56280913e-07]\n",
            " [9.99999285e-01 7.58194460e-07]\n",
            " [9.99999285e-01 6.63604851e-07]\n",
            " [9.99998450e-01 1.49610582e-06]\n",
            " [9.99999523e-01 4.73047834e-07]\n",
            " [9.99996543e-01 3.48349658e-06]\n",
            " [9.99997735e-01 2.31686749e-06]\n",
            " [9.99999404e-01 6.24725089e-07]\n",
            " [9.99999285e-01 7.31322700e-07]\n",
            " [9.99995589e-01 4.36161918e-06]\n",
            " [9.99994040e-01 5.93537425e-06]\n",
            " [9.99998689e-01 1.34753157e-06]\n",
            " [9.99998569e-01 1.38971279e-06]\n",
            " [9.99994636e-01 5.31644082e-06]\n",
            " [9.99998927e-01 1.01786907e-06]\n",
            " [9.99958754e-01 4.12103909e-05]\n",
            " [9.99998808e-01 1.19804645e-06]\n",
            " [9.99999404e-01 5.67709890e-07]\n",
            " [9.99999046e-01 9.09233790e-07]\n",
            " [9.99998927e-01 1.01596629e-06]\n",
            " [9.99997854e-01 2.08996789e-06]\n",
            " [9.99999523e-01 4.77497395e-07]\n",
            " [9.99996066e-01 3.87795944e-06]\n",
            " [9.99992251e-01 7.71345003e-06]\n",
            " [9.99999285e-01 7.36289223e-07]\n",
            " [9.99999404e-01 6.04326374e-07]\n",
            " [9.99996305e-01 3.75148625e-06]\n",
            " [9.99999523e-01 4.96561881e-07]\n",
            " [9.99998927e-01 1.04097217e-06]\n",
            " [9.99983668e-01 1.63447676e-05]\n",
            " [9.99999523e-01 4.81611607e-07]\n",
            " [9.99981523e-01 1.85057361e-05]\n",
            " [9.99984622e-01 1.53983055e-05]\n",
            " [9.99997258e-01 2.77868094e-06]\n",
            " [9.99997973e-01 2.00923409e-06]\n",
            " [9.99999523e-01 4.59484284e-07]\n",
            " [9.99998927e-01 1.05179743e-06]\n",
            " [9.99999762e-01 2.14581050e-07]\n",
            " [9.99986172e-01 1.38381374e-05]\n",
            " [9.99999166e-01 8.39455197e-07]\n",
            " [9.99999523e-01 5.35986942e-07]\n",
            " [9.99998450e-01 1.50144297e-06]\n",
            " [9.99999046e-01 9.23724770e-07]\n",
            " [9.99996662e-01 3.31114029e-06]\n",
            " [9.99998927e-01 1.07203709e-06]\n",
            " [9.99998927e-01 1.06440473e-06]\n",
            " [9.99987960e-01 1.20543755e-05]\n",
            " [9.99999642e-01 4.02665705e-07]\n",
            " [9.99995828e-01 4.11600467e-06]\n",
            " [9.99999046e-01 1.00546401e-06]\n",
            " [9.99998808e-01 1.19402455e-06]\n",
            " [9.99938846e-01 6.11628202e-05]\n",
            " [9.99987006e-01 1.29549608e-05]\n",
            " [9.99989510e-01 1.05100598e-05]\n",
            " [9.99999166e-01 8.30081262e-07]\n",
            " [9.99999285e-01 7.57691339e-07]\n",
            " [9.99997973e-01 1.97366103e-06]\n",
            " [9.99997258e-01 2.70496616e-06]\n",
            " [9.99999404e-01 6.19114928e-07]\n",
            " [9.99999523e-01 4.35593932e-07]\n",
            " [9.99998689e-01 1.26323425e-06]\n",
            " [9.99999285e-01 6.91649348e-07]\n",
            " [9.99999523e-01 4.80397432e-07]\n",
            " [9.99999046e-01 9.13005749e-07]\n",
            " [9.99999523e-01 4.86955173e-07]\n",
            " [9.99999642e-01 3.54545989e-07]\n",
            " [9.99997020e-01 2.97983252e-06]\n",
            " [9.99997020e-01 3.03069191e-06]\n",
            " [9.99998927e-01 1.10537769e-06]\n",
            " [9.99994278e-01 5.68812811e-06]\n",
            " [9.99999285e-01 7.61244678e-07]\n",
            " [9.99999285e-01 6.73356055e-07]\n",
            " [9.99998927e-01 1.05646802e-06]\n",
            " [9.99997973e-01 2.04473827e-06]\n",
            " [9.99999285e-01 7.61607737e-07]\n",
            " [9.99999404e-01 6.43292765e-07]\n",
            " [9.99999166e-01 8.42283555e-07]\n",
            " [9.99988198e-01 1.18500084e-05]\n",
            " [9.99998331e-01 1.71007662e-06]\n",
            " [9.99999166e-01 8.72368503e-07]\n",
            " [9.99999166e-01 7.91398520e-07]\n",
            " [9.99989390e-01 1.05889940e-05]\n",
            " [9.99998808e-01 1.18969854e-06]\n",
            " [9.99985218e-01 1.47652891e-05]\n",
            " [9.99999642e-01 4.13379979e-07]\n",
            " [9.99999166e-01 8.88888394e-07]\n",
            " [9.99997735e-01 2.31247895e-06]\n",
            " [9.99998689e-01 1.35451342e-06]\n",
            " [9.99998450e-01 1.54751501e-06]\n",
            " [9.99998808e-01 1.13717942e-06]\n",
            " [9.99992013e-01 7.93607705e-06]\n",
            " [9.99998927e-01 1.05014669e-06]\n",
            " [9.99998808e-01 1.16308706e-06]\n",
            " [9.99994993e-01 5.01475415e-06]\n",
            " [9.99998927e-01 1.11119289e-06]\n",
            " [9.99999285e-01 7.27913175e-07]\n",
            " [9.99999285e-01 6.73181432e-07]\n",
            " [9.99992967e-01 7.01915633e-06]\n",
            " [9.99993682e-01 6.36444611e-06]\n",
            " [9.99997497e-01 2.52658970e-06]\n",
            " [9.99999404e-01 5.94343476e-07]\n",
            " [9.99992371e-01 7.67270376e-06]\n",
            " [9.99997258e-01 2.79809069e-06]\n",
            " [9.99996066e-01 3.96564337e-06]\n",
            " [9.99999285e-01 7.17664079e-07]\n",
            " [9.99998212e-01 1.81251244e-06]\n",
            " [9.99997020e-01 3.03700836e-06]\n",
            " [9.99998331e-01 1.69538407e-06]\n",
            " [9.99999523e-01 5.00300359e-07]\n",
            " [9.99999046e-01 9.44713577e-07]\n",
            " [9.99991179e-01 8.78069477e-06]\n",
            " [9.99998093e-01 1.88156821e-06]\n",
            " [9.99997854e-01 2.13517433e-06]\n",
            " [9.99999642e-01 2.98833640e-07]\n",
            " [9.99998689e-01 1.30319700e-06]\n",
            " [9.99999404e-01 5.76846844e-07]\n",
            " [9.99997616e-01 2.40617806e-06]\n",
            " [9.99999404e-01 5.54755616e-07]\n",
            " [9.99999404e-01 6.49949698e-07]\n",
            " [9.99999046e-01 9.88794454e-07]\n",
            " [9.99998927e-01 1.09666564e-06]\n",
            " [9.99990463e-01 9.54249663e-06]\n",
            " [9.99993920e-01 6.09386734e-06]\n",
            " [9.99995589e-01 4.43303452e-06]\n",
            " [9.99997735e-01 2.27821715e-06]\n",
            " [9.99998808e-01 1.14926820e-06]\n",
            " [9.99999166e-01 8.86410589e-07]\n",
            " [9.99999166e-01 7.89512455e-07]\n",
            " [9.99990106e-01 9.86493615e-06]\n",
            " [9.99998927e-01 1.12608427e-06]\n",
            " [9.99996066e-01 3.89525030e-06]\n",
            " [9.99991298e-01 8.64670619e-06]\n",
            " [9.99998808e-01 1.23123402e-06]\n",
            " [9.99999523e-01 5.21946049e-07]\n",
            " [9.99997139e-01 2.83179952e-06]\n",
            " [9.99995470e-01 4.49364688e-06]\n",
            " [9.99998927e-01 1.10514577e-06]\n",
            " [9.99997497e-01 2.50065000e-06]\n",
            " [9.99999046e-01 9.35741525e-07]\n",
            " [9.99995708e-01 4.34429194e-06]\n",
            " [9.99999523e-01 5.22691721e-07]\n",
            " [9.99988556e-01 1.14179329e-05]\n",
            " [9.99999166e-01 8.46654984e-07]\n",
            " [9.99995112e-01 4.90018101e-06]\n",
            " [9.99996662e-01 3.37541292e-06]\n",
            " [9.99995470e-01 4.58712930e-06]\n",
            " [9.99992847e-01 7.18962065e-06]\n",
            " [9.99999285e-01 6.62418643e-07]\n",
            " [9.99991417e-01 8.59535521e-06]\n",
            " [9.99993801e-01 6.15488898e-06]\n",
            " [9.99981403e-01 1.85606641e-05]\n",
            " [9.99998689e-01 1.27499493e-06]\n",
            " [9.99997854e-01 2.10055032e-06]\n",
            " [9.99997377e-01 2.59523790e-06]\n",
            " [9.99997139e-01 2.84063344e-06]\n",
            " [9.99998927e-01 1.07661276e-06]\n",
            " [9.99997020e-01 3.01133150e-06]\n",
            " [9.99995947e-01 4.06958179e-06]\n",
            " [9.99997735e-01 2.27285909e-06]\n",
            " [9.99999404e-01 5.65865605e-07]\n",
            " [9.99998927e-01 1.08739891e-06]\n",
            " [9.99995112e-01 4.88581327e-06]\n",
            " [9.99998569e-01 1.38037421e-06]\n",
            " [9.99996901e-01 3.09235952e-06]\n",
            " [9.99984622e-01 1.54074423e-05]\n",
            " [9.99997020e-01 2.92662094e-06]\n",
            " [9.99983668e-01 1.62790748e-05]\n",
            " [9.99940276e-01 5.96751088e-05]\n",
            " [9.99998450e-01 1.51839686e-06]\n",
            " [9.99999642e-01 3.83611223e-07]\n",
            " [9.99997616e-01 2.40159079e-06]\n",
            " [9.99993563e-01 6.44042575e-06]]\n",
            "1.0\n",
            "468\n",
            "468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kXMZEYcl4VaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7d0c1ff-f92d-48f5-d045-3638c3a97fe7"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "score=precision_recall_fscore_support((label[0:468,0]), pred[0:468,0].round(), average='macro')\n",
        "#precision_recall_fscore_support((label[858:1715,1]), pred[858:1715,1].round(), average='macro')\n",
        "#print(label[858:1715,1])\n",
        "#print( pred[858:1715,1])\n",
        "#print( pred[0:858,0])\n",
        "print (score)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1.0, 1.0, 1.0, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jMoPHtvJ4fdv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}